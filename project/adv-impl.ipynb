{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.sparse import csr_matrix, find\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13575, 2638)\n",
      "(13575, 529)\n",
      "(13575, 1803)\n",
      "(839, 2638)\n",
      "(839, 529)\n",
      "(839, 1803)\n"
     ]
    }
   ],
   "source": [
    "data = Data()\n",
    "train_X, train_S, train_R = data.load(\"0*\", True)\n",
    "print train_X.shape\n",
    "print train_R.shape\n",
    "print train_S.shape\n",
    "val_X, val_S, val_R = data.load(\"ff*\")\n",
    "print val_X.shape\n",
    "print val_R.shape\n",
    "print val_S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import gammaln\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "\n",
    "class CombinedMultinomialBayesianNaiveBayes():\n",
    "    \n",
    "    def __init__(self, eta=0.0, alpha = 0.1, beta=0.01):\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "    def betaln(self, x, axis):\n",
    "        return np.sum(gammaln(x), axis=axis) - gammaln(np.sum(x, axis=axis))\n",
    "    \n",
    "    def fit(self, X, R, S):\n",
    "        \"\"\"\n",
    "        X: sparse n-samples x n-words\n",
    "        R: sparse (one hot) n-samples x n-receivers\n",
    "        S: sparse (one hot) n-samples x n-senders\n",
    "        \"\"\"\n",
    "        self.m = R.sum(axis=0).A.T             # n-receivers x 1 \n",
    "        self.c = safe_sparse_dot(R.T, S)     # n-receivers x n-senders\n",
    "        \n",
    "        self.lrp = np.log(self.eta + self.m) # n-receivers x 1\n",
    "        k = self.alpha + self.c.toarray()\n",
    "        self.lrsp = np.log(k) - np.log(np.sum(k, axis=1, keepdims=True)) # n-receivers x n-senders\n",
    "        \n",
    "        r = np.argmax(R.toarray(), axis=1)\n",
    "        s = np.argmax(S.toarray(), axis=1)\n",
    "        \n",
    "        self.W = list()                      # n-receivers x n-senders x n-words\n",
    "        for i in range(R.shape[1]):\n",
    "            self.W.append(lil_matrix((S.shape[1], X.shape[1])))\n",
    "            \n",
    "        for i in range(X.shape[0]):\n",
    "            self.W[r[i]][s[i],:] += X[i,:]\n",
    "        \n",
    "        for i in range(R.shape[1]):\n",
    "            self.W[i] = csr_matrix(self.W[i])\n",
    "        \n",
    "    def predict_log_proba(self, x):\n",
    "        \"\"\"\n",
    "        x: sparse n-samples x n-features\n",
    "        \"\"\"\n",
    "        lp = np.zeros((x.shape[0], self.lrsp.shape[0], self.lrsp.shape[1]))\n",
    "        for i in range(x.shape[0]):\n",
    "            for l in range(self.lrsp.shape[0]):\n",
    "                _,j,xj = find(x[i,:])\n",
    "                wj = self.W[l][:,j].toarray() + self.beta\n",
    "                a = self.betaln(wj + xj, axis=1)\n",
    "                b = self.betaln(wj, axis=1)\n",
    "                lp[i,l,:] = self.lrp[l] + self.lrsp[l] + a - b\n",
    "\n",
    "        return lp\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x: sparse n-samples x n-features\n",
    "        \"\"\"\n",
    "        lp = self.predict_log_proba(x)\n",
    "\n",
    "        return zip(*[np.unravel_index(np.argmax(p),p.shape) for p in lp])\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"\n",
    "        x: sparse n-samples x n-features\n",
    "        \"\"\"\n",
    "        lp = self.predict_log_proba(x)\n",
    "        lp -= lp.max(axis=1, keepdims=True)\n",
    "        p = np.exp(lp)\n",
    "        return p/p.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = CombinedMultinomialBayesianNaiveBayes()\n",
    "nb.fit(train_X, train_R, train_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_r, pred_s = nb.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_r = np.argmax(val_R.toarray(),axis=1)\n",
    "val_s = np.argmax(val_S.toarray(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909415971395\n",
      "0.828563704997\n",
      "0.907714549346\n",
      "\n",
      "\n",
      "0.814064362336\n",
      "0.439955234229\n",
      "0.810424417683\n"
     ]
    }
   ],
   "source": [
    "print f1_score(val_s, pred_s, average='micro')\n",
    "print f1_score(val_s, pred_s, average='macro')\n",
    "print f1_score(val_s, pred_s, average='weighted')\n",
    "print \"\\n\"\n",
    "print f1_score(val_r, pred_r, average='micro')\n",
    "print f1_score(val_r, pred_r, average='macro')\n",
    "print f1_score(val_r, pred_r, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
